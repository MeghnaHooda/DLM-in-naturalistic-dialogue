# DLM-in-naturalistic-dialogue

"Data_Dialogue" consist of baselines generated from Hindi Dialogue Corpus.
"Data_Text" consist of baselines generated from HDTB.
 FOr more information on how to generate baselines please refer to following citation:
Himanshu Yadav, Shubham Mittal, Samar Husain; A Reappraisal of Dependency Length Minimization as a Linguistic Universal. Open Mind 2022; 6 147â€“168. doi: https://doi.org/10.1162/opmi_a_00060


"Dialogue Corpus Filtered" consist of python code to filter the Hindi Dialogue Corpus. Filtering criteria is mentioned in the readme inside the folder

"Measures" consist of code to calculate dependency length, dependency direction, number of crossings. This code is used in other programs.

"graphs" consist of graphs obtained from the Analysis

"DLM Baseline" is for the analysis of dependency length minimisation
"Long Before Short" is to recognise and analyse long before short order for arguments and adjuncts.
"Right Extraposition" is to collect non project instances and analyse them.

They all consists of:
1. a python file to compute the numbers from raw baseline data
2. Rmd file which shows the analysis and model fitting
3. pdf file obtained from the rmd file which shows the data structure and model output
4. Output of the python file
